{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ff7130",
   "metadata": {},
   "source": [
    "# Resume Screening\n",
    "-  https://www.analyticsvidhya.com/blog/2021/06/resume-screening-with-natural-language-processing-in-python/\n",
    "-  https://github.com/anukalp-mishra/Resume-Screening/blob/main/Resume_Screening.ipynb\n",
    "-  https://github.com/Oindrila-Sen/Python-Projects/blob/master/Resume_Scanner/resume_scanner.ipynb\n",
    "-  https://towardsdatascience.com/pdfs-to-word-cloud-in-3-steps-73ccbff6d835\n",
    "Libraries\n",
    "-  PyPDF2 : to parse the PDF file (method 1)\n",
    "-  textract : to parse the PDF file (method 1)\n",
    "-  wordcloud : to create the word cloud image\n",
    "-  nltk : to get the stopwords and to tokenize the string to keywords\n",
    "-  collection : to get the mapping of keywords to its occurrence count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "007a9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install\n",
    "#!pip install docx2txt\n",
    "#!pip install PyPDF2\n",
    "#!pip install pdfreader\n",
    "#!pip install pdfminer\n",
    "#!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "233cdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca4f1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import PyPDF2\n",
    "import textract\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "# Docx resume\n",
    "import docx2txt\n",
    "\n",
    "#Wordcloud\n",
    "import re\n",
    "import operator\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "from wordcloud import WordCloud\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba99419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf scanner\n",
    "def read_pdf_resume(pdf_doc):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    \n",
    "    with open(pdf_doc, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "            \n",
    "        text = fake_file_handle.getvalue()\n",
    "    \n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "    \n",
    "    if text:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13840761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word resume\n",
    "def read_word_resume(word_doc):\n",
    "     resume = docx2txt.process(word_doc)\n",
    "     resume = str(resume)\n",
    "     #print(resume)\n",
    "     text =  ''.join(resume)\n",
    "     text = text.replace(\"\\n\", \"\")\n",
    "     if text:\n",
    "         return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6765c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JD from file\n",
    "def read_JD_from_word(word_doc):\n",
    "     jdText = docx2txt.process(word_doc)\n",
    "     jdText = str(jdText)\n",
    "     #print(resume)\n",
    "     text =  ''.join(jdText)\n",
    "     text = text.replace(\"\\n\", \"\")\n",
    "     if text:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dd57c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean JD\n",
    "def clean_job_description(jd):\n",
    "     ''' a function to create a word cloud based on the input text parameter'''\n",
    "     ## Clean the Text\n",
    "     # Lower\n",
    "     clean_jd = jd.lower()\n",
    "     # remove punctuation\n",
    "     clean_jd = re.sub(r'[^\\w\\s]', '', clean_jd)\n",
    "     # remove trailing spaces\n",
    "     clean_jd = clean_jd.strip()\n",
    "     # remove numbers\n",
    "     clean_jd = re.sub('[0-9]+', '', clean_jd)\n",
    "     # tokenize \n",
    "     clean_jd = word_tokenize(clean_jd)\n",
    "     # remove stop words\n",
    "     stop = stopwords.words('english')\n",
    "     clean_jd = [w for w in clean_jd if not w in stop] \n",
    "     return(clean_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e277903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a word cloud:\n",
    "# create_word_cloud(jd, wd=50): max_words = wd, \n",
    "def create_word_cloud(jd):\n",
    "    corpus = jd\n",
    "    fdist = FreqDist(corpus)\n",
    "    #print(fdist.most_common(100))\n",
    "    words = ' '.join(corpus)\n",
    "    words = words.split()\n",
    "\n",
    "    # create a empty dictionary\n",
    "    data = dict()\n",
    "    #  Get frequency for each words where word is the key and the count is the value\n",
    "    for word in (words):\n",
    "        word = word.lower()\n",
    "        data[word] = data.get(word, 0) + 1\n",
    "    # Sort the dictionary in reverse order to print first the most used terms    \n",
    "    dict(sorted(data.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    word_cloud = WordCloud(width = 800, height = 800, background_color ='white',max_words = 500)\n",
    "    word_cloud.generate_from_frequencies(data)\n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (10, 8), edgecolor = 'k') \n",
    "    plt.imshow(word_cloud,interpolation = 'bilinear') \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0471b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Job Description and Resume Match Score\n",
    "def get_resume_score(cvName, text):\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    count_matrix = cv.fit_transform(text)\n",
    "    #Print the similarity scores\n",
    "    print(\"\\nSimilarity Scores:\")\n",
    "     \n",
    "    #get the match percentage\n",
    "    matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
    "    matchPercentage = round(matchPercentage, 2) # round to two decimal\n",
    "     \n",
    "    print(\"Your resume \" + str(cvName) + \" matches about \" + str(matchPercentage)+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b7debae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_pypdf(filepath):\n",
    "    pdfFileObj = open(filepath,'rb')\n",
    "    pdfReader = PyPDF2.pdfReader(pdfFileObj)\n",
    "    num_pages = reader.pages(pg)\n",
    "    text = \"\"\n",
    "    # Read all the pages\n",
    "    for pg in range(num_pages):\n",
    "        page = pdfReader.getPage(pg)\n",
    "        text += page.extractText()\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a139fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_textract(filepath, use_method = 'textract'):\n",
    "    \n",
    "    text = \"\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(f'Invalid file:{filepath}')\n",
    "    else:\n",
    "        if use_method == 'textract':\n",
    "            return read_file_textract(filepath)\n",
    "        elif use_method == 'pypdf':\n",
    "            return read_file_pypdf(filepath)\n",
    "        else:\n",
    "            print('Invalid method to read file. Supported formats: \"textract\" or \"pypdf\".')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "548f7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text, ignore_words = [],   min_word_length = 0, ignore_numbers = True,  ignore_case = True):\n",
    "    # Remove words with special characters\n",
    "    filtered_text = ''.join(filter(lambda x:x in string.printable, text))\n",
    "    \n",
    "    # Create word tokens from the text string\n",
    "    tokens = word_tokenize(filtered_text)\n",
    "    \n",
    "    # List of punctuations to be ignored \n",
    "    punctuations = ['(',')',';',':','[',']',',','.','--','-','#','!','*','\"','%']\n",
    "    \n",
    "    # Get the stopwords list to be ignored\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # Convert ignore words from user to lower case\n",
    "    ignore_words_lower = [x.lower() for x in ignore_words]\n",
    "    \n",
    "    # Combine all the words to be ignored\n",
    "    all_ignored_words = punctuations + stop_words + ignore_words_lower\n",
    "    \n",
    "    # Get the keywords list\n",
    "    keywords = [word for word in tokens \\\n",
    "                    if  word.lower() not in all_ignored_words\n",
    "                    and len(word) >= min_word_length]    \n",
    "\n",
    "    # Remove keywords with only digits\n",
    "    if ignore_numbers:\n",
    "        keywords = [keyword for keyword in keywords if not keyword.isdigit()]\n",
    "\n",
    "    # Return all keywords in lower case if case is not of significance\n",
    "    if ignore_case:\n",
    "        keywords = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0a720f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_cloud2(keywords, maximum_words = 100, bg = 'white', cmap='Dark2', maximum_font_size = 256, width = 3000, height = 2000,\n",
    "                     random_state = 42, fig_w = 15, fig_h = 10, output_filepath = None):\n",
    "    \n",
    "    # Convert keywords to dictionary with values and its occurences\n",
    "    word_could_dict=Counter(keywords)\n",
    "\n",
    "    wordcloud = WordCloud(background_color=bg, max_words=maximum_words, colormap=cmap, \n",
    "                          stopwords=STOPWORDS, max_font_size=maximum_font_size,\n",
    "                          random_state=random_state, \n",
    "                          width=width, height=height).generate_from_frequencies(word_could_dict)\n",
    "    \n",
    "    plt.figure(figsize=(fig_w,fig_h))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    if output_filepath:\n",
    "        plt.savefig(output_filepath, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "717fad3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'E:/auData/hr/cv/cvset1/DrJAnitha.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/auData/hr/cv/cvset1/\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m filepath\u001b[38;5;241m=\u001b[39mcvPDF\n\u001b[1;32m----> 8\u001b[0m os\u001b[38;5;241m.\u001b[39mlistdir(filepath)\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'E:/auData/hr/cv/cvset1/DrJAnitha.pdf'"
     ]
    }
   ],
   "source": [
    "#name='main'\n",
    "jdFile = 'E:/auData/hr/cv/cvset1/jdFaculty.docx'\n",
    "cvPDF = 'E:/auData/hr/cv/cvset1/DrJAnitha.pdf'\n",
    "cvName ='DrJAnitha'\n",
    "#cvWord  = 'E:/auData/hr/cv/cvset1/DrSwaranlatha.docx'\n",
    "', '.join(os.listdir('E:/auData/hr/cv/cvset1/'))\n",
    "filepath=cvPDF\n",
    "os.listdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b504b8e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/auData/hr/cv/DrJAnitha.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#manual way\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filepath\u001b[38;5;241m=\u001b[39mcvPDF\n\u001b[1;32m----> 3\u001b[0m file_text \u001b[38;5;241m=\u001b[39m read_file_pypdf(filepath)\n\u001b[0;32m      4\u001b[0m keywords \u001b[38;5;241m=\u001b[39m extract_keywords(file_text, min_word_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      5\u001b[0m create_word_cloud2(keywords,maximum_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m, in \u001b[0;36mread_file_pypdf\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file_pypdf\u001b[39m(filepath):\n\u001b[1;32m----> 2\u001b[0m     pdfFileObj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filepath,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m     pdfReader \u001b[38;5;241m=\u001b[39m PyPDF2\u001b[38;5;241m.\u001b[39mpdfReader(pdfFileObj)\n\u001b[0;32m      4\u001b[0m     num_pages \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mpages(pg)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/auData/hr/cv/DrJAnitha.pdf'"
     ]
    }
   ],
   "source": [
    "#manual way\n",
    "filepath=cvPDF\n",
    "file_text = read_file_pypdf(filepath)\n",
    "keywords = extract_keywords(file_text, min_word_length = 3)\n",
    "create_word_cloud2(keywords,maximum_words=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7864bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e550f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Resume Scanner:\n",
    "if __name__ == '__main__':\n",
    "    extn = input(\"Enter File Extension: \")\n",
    "    #print(extn)\n",
    "    if extn == \"pdf\":\n",
    "        resume = read_pdf_resume(cvPDF)\n",
    "    else:\n",
    "        resume = read_word_resume(cvWord)\n",
    "    \n",
    "    #JD  = input(\"\\nEnter the Job Description: \") \n",
    "    JD =  read_JD_from_word(jdFile) \n",
    "    ## Get a Keywords Cloud \n",
    "    clean_jd = clean_job_description(JD) \n",
    "    print('Word Cloud of KeyWords of Job Desciption')\n",
    "    create_word_cloud(clean_jd)\n",
    "    \n",
    "    print(\"Word Cloud of Keywords from CV\")\n",
    "    create_word_cloud(resume)\n",
    "    create_word_cloud(clean_job_description(cvWord))\n",
    "    text = [resume, JD] \n",
    "    \n",
    "    ## Get a Match score\n",
    "    get_resume_score(cvName, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806baa3",
   "metadata": {},
   "source": [
    "Job Description: University Faculty Member\n",
    "Position Overview:\n",
    "The University Faculty Member is a dedicated and passionate educator responsible for delivering high-quality instruction, conducting research, and contributing to the academic and professional growth of students within a specific discipline. This role involves engaging in scholarly activities, collaborating with colleagues, and participating in curriculum development to maintain and enhance the university's academic standards.\n",
    "Key Responsibilities: \n",
    "1. Teaching and Instruction: \n",
    "   - Design and deliver engaging and effective course materials that align with the curriculum and learning objectives.\n",
    "   - Conduct lectures, seminars, workshops, and practical sessions to facilitate student understanding and skill development.\n",
    "   - Provide timely and constructive feedback on assignments, projects, and examinations to support student progress.\n",
    "2. Research and Scholarship:\n",
    "   - Conduct original research in the relevant field, contributing to the advancement of knowledge and the discipline.\n",
    "   - Publish research findings in peer-reviewed journals, present at conferences, and participate in scholarly discussions.\n",
    "   - Seek and secure research grants and funding to support research endeavours.\n",
    "3. Student Mentorship:\n",
    "   - Advise and mentor students on academic, research, and career-related matters.\n",
    "   - Foster a supportive and inclusive learning environment that promotes student success and personal growth.\n",
    "   - Assist students in developing critical thinking, problem-solving skills, and a strong academic foundation.\n",
    "\n",
    "4. Curriculum Development:\n",
    "   - Collaborate with colleagues to develop and update course curricula, ensuring relevance to industry trends and academic standards.\n",
    "   - Integrate innovative teaching methods, technology, and experiential learning opportunities to enhance the learning experience.\n",
    "\n",
    "5. Service and Collaboration:\n",
    "   - Participate in departmental meetings, committees, and academic governance activities to contribute to the university's decision-making processes.\n",
    "   - Collaborate with colleagues to develop interdisciplinary programs, research initiatives, and community engagement projects.\n",
    "   - Engage with professional organizations and external stakeholders to foster partnerships and promote the university's reputation.\n",
    "\n",
    "6. Professional Development:\n",
    "   - Stay current with developments in the field through continuous learning, attending conferences, workshops, and other professional development opportunities.\n",
    "   - Pursue tenure and promotion milestones as per university guidelines, demonstrating excellence in teaching, research, and service.\n",
    "\n",
    "Qualifications:\n",
    "\n",
    "- A doctoral degree (Ph.D. or equivalent) in the relevant field.\n",
    "- Strong passion for teaching, demonstrated by previous teaching experience, evaluations, and/or awards.\n",
    "- Active research agenda with a record of scholarly publications and presentations.\n",
    "- Excellent communication and interpersonal skills to effectively engage with students, colleagues, and external partners.\n",
    "- Commitment to diversity, equity, and inclusion in teaching, research, and service activities.\n",
    "- Ability to work collaboratively in a team-oriented academic environment.\n",
    "- Proficiency in utilizing technology and innovative teaching methods for enhancing student learning.\n",
    "- Experience in curriculum development and assessment is a plus.\n",
    "- Previous grant-writing and research funding acquisition experience is desirable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d9e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
